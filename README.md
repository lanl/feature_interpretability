[//]: <> (THIS IS A MARKDOWN FILE, VIEW IN A MARKDOWN VIEWER OR CONVERT)

# Feature Interpretability

This folder of code contains tools for extracting, plotting, and computing with features extracted from nerual networks. While these tools are intended to be easily maluable to new networks and new datasets, they are not guarenteed to work outside of these settings.

These tools were developed by **Skylar Callis**. They developed this code while working as a post-bachelors student at [Los Alamos National Laboratory (LANL)](https://www.lanl.gov/?source=globalheader) from 2022 - 2024. To see what they are up to these days, visit [Skylar's Website ](https://skylar-jean.com).

The feature interpertability code has been approved by LANL for a BSD-3 open source license under O#4675.

The documentation for this code can be found [locally](./docs/html/index.html) and [hosted on GitHub](https://lanl.github.io/feature_interpretability/html/index.html).

The GitHub page for this code can be found at [here](https://github.com/lanl/feature_interpretability).

More details about the use of feature interpretability on the LANL coupon problem can be found in:

>Hickmann, K, Callis, S, & Andrews, S. “Training and Interpretability of Deep-Neural Methods for Damage Calibration in Copper.” Proceedings of the ASME 2023 Verification, Validation, and Uncertainty Quantification Symposium. ASME 2023 Verification, Validation, and Uncertainty Quantification Symposium. Baltimore, Maryland, USA. May 17–19, 2023. V001T04A001. ASME. https://doi.org/10.1115/VVUQ2023-108759
